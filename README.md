# ğŸ§  Sentence-Level Small Language Model (SLM) with GPT2

This project demonstrates a lightweight implementation of a **small language model (SLM)** using the **GPT2** architecture via Hugging Face ğŸ¤— Transformers.

It supports **text generation** in both **Persian and English**, making it ideal for educational use, rapid experimentation, and low-resource environments.

---

## âœ¨ Features

- âœ… Based on the compact GPT2 model: `openai-community/gpt2`
- ğŸ§  Suitable as a **small language model** (SLM) for quick testing and concept validation
- ğŸ—£ï¸ Supports **bilingual prompts**: Farsi (ÙØ§Ø±Ø³ÛŒ) & English
- âš¡ Fast execution with minimal dependencies
- ğŸ” Easily extendable for fine-tuning or creative applications (e.g., poetry, Q&A, storytelling)

---

## ğŸ“¦ Installation

Install required packages using pip:

```bash
pip install transformers accelerate torch
````

---

## ğŸš€ How It Works

1. Load the GPT2 model and tokenizer from Hugging Face Hub
2. Define a generation function with parameters like temperature and top-p
3. Provide a **prompt in Farsi or English**
4. Generate text continuation using the `generate()` method

---

## ğŸ“‹ Example Prompts

```python
# Persian example
prompt = "Ú†Ø±Ø§ Ø¢Ø³Ù…Ø§Ù† Ø¢Ø¨ÛŒ Ø§Ø³ØªØŸ"

# English example
prompt = "Write a short story about a brave knight and a dragon."
```

Sample output:

```
Prompt (ÙØ§Ø±Ø³ÛŒ): Ú†Ø±Ø§ Ø¢Ø³Ù…Ø§Ù† Ø¢Ø¨ÛŒ Ø§Ø³ØªØŸ
Generated: Ø¨Ù‡ Ø¯Ù„ÛŒÙ„ Ù¾Ø±Ø§Ú©Ù†Ø¯Ú¯ÛŒ Ù†ÙˆØ± Ø®ÙˆØ±Ø´ÛŒØ¯ ØªÙˆØ³Ø· Ø¬Ùˆ Ø²Ù…ÛŒÙ†ØŒ Ø¨ÛŒØ´ØªØ± Ù†ÙˆØ± Ø¢Ø¨ÛŒ Ø¯ÛŒØ¯Ù‡ Ù…ÛŒâ€ŒØ´ÙˆØ¯...

Prompt (English): Write a short story about a brave knight...
Generated: ...who ventured into the mountains to protect his village from the dragon...
```

---

## ğŸ“ Project Structure

```
slm.py                # Main Python script for bilingual text generation
README.md             # Project description and instructions
```

---

## ğŸ’¡ Use Cases

* Bilingual prompt testing
* Educational demos for language modeling
* Creative writing, poetry, or storytelling
* Exploring small LLM behavior in controlled setups

---

## ğŸ› ï¸ Built With

* [Transformers](https://huggingface.co/docs/transformers)
* [PyTorch](https://pytorch.org/)
* [Accelerate](https://github.com/huggingface/accelerate)

---


