# -*- coding: utf-8 -*-
"""slm.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/13uPf5PiwySGsNNXWLCgMPbGVDVK76oWO
"""

!pip install -q transformers accelerate

import torch
from transformers import AutoModelForCausalLM, AutoTokenizer

model_name = "openai-community/gpt2"

print(f"Loading model: {model_name}...")
model = AutoModelForCausalLM.from_pretrained(
    model_name,
    device_map="auto",
    trust_remote_code=True,
)
print("Model loaded successfully.")

print(f"Loading tokenizer: {model_name}...")
tokenizer = AutoTokenizer.from_pretrained(model_name)
print("Tokenizer loaded successfully.")

def generate_text(prompt, max_new_tokens=256, temperature=0.7, top_p=0.9):

    input_ids = tokenizer(prompt, return_tensors="pt").to(model.device)


    print("\nGenerating text...")
    outputs = model.generate(
        **input_ids,
        max_new_tokens=max_new_tokens,
        temperature=temperature,
        top_p=top_p,
        do_sample=True,

    )


    generated_text = tokenizer.decode(outputs[0], skip_special_tokens=True)

    if generated_text.startswith(prompt):
        return generated_text[len(prompt):].strip()
    return generated_text.strip()


prompt_fa = "چرا آسمان آبی است؟"
print(f"Prompt (فارسی): {prompt_fa}")
generated_fa = generate_text(prompt_fa)
print(f"Generated Text (فارسی): \n{generated_fa}\n")


prompt_en = "Write a short story about a brave knight and a dragon."
print(f"Prompt (انگلیسی): {prompt_en}")
generated_en = generate_text(prompt_en)
print(f"Generated Text (انگلیسی): \n{generated_en}\n")

# می‌توانید با پرامپت‌های خودتان آزمایش کنید:
# my_prompt = "یک شعر کوتاه در مورد پاییز بنویس:"
# print(f"My Prompt: {my_prompt}")
# my_generated_text = generate_text(my_prompt)
# print(f"My Generated Text: \n{my_generated_text}\n")